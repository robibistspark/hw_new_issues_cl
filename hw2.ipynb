{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from razdel import tokenize\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier as RandFor\n",
    "from sklearn.tree import DecisionTreeClassifier as DecTree\n",
    "from sklearn.naive_bayes import MultinomialNB as NaiveB\n",
    "from string import punctuation as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6942</td>\n",
       "      <td>У нас до сих пор по городу такие тралики ходят\\n</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7417</td>\n",
       "      <td>Интересно, как на ней происходит корректировка...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5503</td>\n",
       "      <td>Было у меня нечто похожее.Тоже на работе сидел...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            comment  toxic\n",
       "0   6942   У нас до сих пор по городу такие тралики ходят\\n    0.0\n",
       "1   7417  Интересно, как на ней происходит корректировка...    0.0\n",
       "2   5503  Было у меня нечто похожее.Тоже на работе сидел...    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизаторы бывают разные (bm25 хотя бы), tfidf по лекции\n",
    "default_tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=5, max_df=0.4)\n",
    "\n",
    "def razdel_tokenize(text):\n",
    "    return [token.text for token in list(tokenize(text))]\n",
    "\n",
    "custom_tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=razdel_tokenize, min_df=5, max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'ясно', 'ящик', 'ёмкости'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1 = default_tfidf_vectorizer.fit_transform(train.comment)\n",
    "x_train_2 = custom_tfidf_vectorizer.fit_transform(train.comment)\n",
    "y_train = train.toxic.values\n",
    "\n",
    "default_tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = default_tfidf_vectorizer.transform(test.comment)\n",
    "x_test_2 = custom_tfidf_vectorizer.transform(test.comment)\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.95      0.88       923\n",
      "         1.0       0.88      0.63      0.74       519\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.85      0.79      0.81      1442\n",
      "weighted avg       0.84      0.84      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogReg()\n",
    "model_1.fit(x_train_1, y_train)\n",
    "preds_1 = model_1.predict(x_test_1)\n",
    "print(classification_report(y_test, preds_1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.95      0.88       923\n",
      "         1.0       0.88      0.65      0.75       519\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.85      0.80      0.81      1442\n",
      "weighted avg       0.85      0.84      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogReg()\n",
    "model_2.fit(x_train_2, y_train)\n",
    "preds_2 = model_2.predict(x_test_2)\n",
    "print(classification_report(y_test, preds_2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом эксперименте кастомный векторизатор оказался лучше по полноте на 0,02 в случае токсичных и хуже по точности на 0,01 в случае нормальных, в итоге f1 у кастомного для токсичных лучше на 0,01, но в целом метрики практически одинаковые"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    tokenizer=razdel_tokenize, \n",
    "    stop_words=stops, \n",
    "    ngram_range=(1, 2), \n",
    "    min_df=5, \n",
    "    max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=razdel_tokenize, \n",
    "    stop_words=stops, \n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5, \n",
    "    max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = count_vectorizer.fit_transform(train.comment)\n",
    "x_test_1 = count_vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = tfidf_vectorizer.fit_transform(train.comment)\n",
    "x_test_2 = tfidf_vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84       923\n",
      "         1.0       0.72      0.71      0.72       519\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.78      0.78      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = RandFor(n_estimators=120, criterion='entropy')\n",
    "model_1.fit(x_train_1, y_train)\n",
    "preds_1 = model_1.predict(x_test_1)\n",
    "print(classification_report(y_test, preds_1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.84      0.86       923\n",
      "         1.0       0.73      0.79      0.76       519\n",
      "\n",
      "    accuracy                           0.82      1442\n",
      "   macro avg       0.80      0.81      0.81      1442\n",
      "weighted avg       0.82      0.82      0.82      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogReg(C=0.1, class_weight='balanced')\n",
    "model_2.fit(x_train_2, y_train)\n",
    "preds_2 = model_2.predict(x_test_2)\n",
    "print(classification_report(y_test, preds_2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(104, 1.0), (204, 1.0), (279, 1.0), (297, 1.0), (535, 1.0), (610, 1.0), (618, 1.0), (677, 1.0), (813, 1.0), (912, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "probs_1 = {}\n",
    "for i, j in enumerate(model_1.predict_proba(x_test_1)):\n",
    "    probs_1[i] = j[1]\n",
    "# в первой колонке -- вероятности токсичных, так что j[1]\n",
    "toxic_1 = sorted(probs_1.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(toxic_1)\n",
    "toxic_1 = [i[0] for i in toxic_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1088, 0.8624018524099621), (31, 0.8584254391870806), (102, 0.8584254391870806), (352, 0.8584254391870806), (437, 0.8584254391870806), (1415, 0.8584254391870806), (1076, 0.8071197438283689), (281, 0.799810291822574), (906, 0.7945795159552033), (985, 0.7932895680478177)]\n"
     ]
    }
   ],
   "source": [
    "probs_2 = {}\n",
    "for i, j in enumerate(model_2.predict_proba(x_test_2)):\n",
    "    probs_2[i] = j[1]\n",
    "toxic_2 = sorted(probs_2.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(toxic_2)\n",
    "toxic_2 = [i[0] for i in toxic_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shared\n"
     ]
    }
   ],
   "source": [
    "for i in toxic_1:\n",
    "    for j in toxic_2:\n",
    "        if i == j:\n",
    "            print(i)\n",
    "else:\n",
    "    print('No shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Теперь хохлов бкдкт травить анашой, чтобы не пиздели на барина.\\n',\n",
       "       'Отписался от долбоеба, все подписки засрал дебил блять\\n',\n",
       "       'Иди нахуй,бля. Я искал эту хуйню так как дрочу в гостиницах, когда в командировки летаю. Сплю бухой без трусов. Мне нужная эта ебень.\\n',\n",
       "       'У хохлов теперь томос есть. То есть нихуя они не провославные, а сектанты ебанные и мрази. А у русни его нет и никогда не было. Учи матчасть, чтобы не быть батхёртом\\n',\n",
       "       'Отправить ты можешь только хуй в свою жопу, лахтодырка.\\n',\n",
       "       'если на борде не будет хохлов то не будет про них постов\\n',\n",
       "       'Какие же пиндосы дегенераты, пиздец просто.\\n',\n",
       "       'Канада пристанище куколдов хохлов, не удивительно что они рашку хейтят.\\n',\n",
       "       'То-то декоммунизированая свиноина процветает, пиздец просто',\n",
       "       'На мотив Славянки. В жопу клюнул жареный петух...\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['comment'].iloc[toxic_1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['БЛЯТЬ! Опять ржу, как представлю минет вприкуску с пирогами! Чувак ты уникум!!!!!\\n',\n",
       "       'А у нас микроминимализм!\\n', 'Пьяного-могила исправит!\\n',\n",
       "       'ты на стол-то ложись, русалка!\\n',\n",
       "       'Чтоб костями не колола, бл ать!\\n',\n",
       "       'азиатский окатыш, не бомби!\\n', 'Замуж тебе надо барыня...\\n',\n",
       "       'А чё, нормуль! Проезду не мешает! Быдло mode off\\n',\n",
       "       'Майдауны ебучие.Их че хохлы там чтоли покусали? Пидары блядь\\n',\n",
       "       'КАКИЕ ХОХЛЫ?! два урода. при чём ту вообще ХОХЛЫ! аноны, смотрите! я двух шлюх проплаченых поймал!\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['comment'].iloc[toxic_2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпадающих текстов в топ-10 нет. Тексты действительно токсичны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"russian\") + [i for i in p] + \\\n",
    "['это', 'тебе', 'очень', 'просто', 'ещё', 'года', '2', '3']\n",
    "# в принципе про \"очень\" можно поспорить, как и про другие\n",
    "\n",
    "def razdel_tokenize(text):\n",
    "    return [token.text for token in list(tokenize(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=razdel_tokenize, \n",
    "    stop_words=stops, \n",
    "    min_df=5, \n",
    "    max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.fit_transform(train.comment)\n",
    "x_test = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       951\n",
      "         1.0       0.74      0.83      0.78       491\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.82      0.84      0.83      1442\n",
      "weighted avg       0.85      0.84      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogReg(C=0.1, class_weight='balanced')\n",
    "model_1.fit(x_train, y_train)\n",
    "preds_1 = model_1.predict(x_test)\n",
    "print(classification_report(y_test, preds_1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>1.530624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>1.508734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>1.270526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>спасибо</td>\n",
       "      <td>1.179985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>блять</td>\n",
       "      <td>1.077598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>блядь</td>\n",
       "      <td>1.060830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>хуй</td>\n",
       "      <td>1.039298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>1.038297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>сука</td>\n",
       "      <td>0.963918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>знаю</td>\n",
       "      <td>0.960377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "7180    хохлы    1.530624\n",
       "7178   хохлов    1.508734\n",
       "3332    нахуй    1.270526\n",
       "6193  спасибо    1.179985\n",
       "445     блять    1.077598\n",
       "444     блядь    1.060830\n",
       "7201      хуй    1.039298\n",
       "4247   пиздец    1.038297\n",
       "6468     сука    0.963918\n",
       "2006     знаю    0.960377"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_1 = pd.DataFrame({\n",
    "    'feature': vectorizer.get_feature_names_out(), \n",
    "    'importance': abs(model_1.coef_[0])\n",
    "})\n",
    "importance_1.sort_values('importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.78      0.81       951\n",
      "         1.0       0.63      0.72      0.67       491\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.74      0.75      0.74      1442\n",
      "weighted avg       0.77      0.76      0.77      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = DecTree(criterion='entropy', class_weight='balanced')\n",
    "model_2.fit(x_train, y_train)\n",
    "preds_2 = model_2.predict(x_test)\n",
    "print(classification_report(y_test, preds_2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>0.012237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>0.010926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>0.008795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>знаю</td>\n",
       "      <td>0.007389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>например</td>\n",
       "      <td>0.006947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>нужно</td>\n",
       "      <td>0.005899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>лет</td>\n",
       "      <td>0.005872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>сука</td>\n",
       "      <td>0.005792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>всё</td>\n",
       "      <td>0.005758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "8          ...    0.012237\n",
       "7180     хохлы    0.010926\n",
       "7178    хохлов    0.008795\n",
       "3332     нахуй    0.008166\n",
       "2006      знаю    0.007389\n",
       "3274  например    0.006947\n",
       "3574     нужно    0.005899\n",
       "2726       лет    0.005872\n",
       "6468      сука    0.005792\n",
       "920        всё    0.005758"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_2 = pd.DataFrame({\n",
    "    'feature': vectorizer.get_feature_names_out(), \n",
    "    'importance': model_2.feature_importances_\n",
    "})\n",
    "importance_2.sort_values('importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.89       951\n",
      "         1.0       0.79      0.80      0.80       491\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.84      0.85      0.84      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = NaiveB(alpha=0.5, fit_prior=False)\n",
    "model_3.fit(x_train, y_train)\n",
    "preds_3 = model_3.predict(x_test)\n",
    "print(classification_report(y_test, preds_3, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5.248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>-5.860254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>-5.918063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>почему</td>\n",
       "      <td>-5.934659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>-6.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>хуй</td>\n",
       "      <td>-6.209338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>блять</td>\n",
       "      <td>-6.245257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>-6.269382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>блядь</td>\n",
       "      <td>-6.277723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>всё</td>\n",
       "      <td>-6.301655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "8        ...   -5.248865\n",
       "7180   хохлы   -5.860254\n",
       "7178  хохлов   -5.918063\n",
       "4811  почему   -5.934659\n",
       "3332   нахуй   -6.001342\n",
       "7201     хуй   -6.209338\n",
       "445    блять   -6.245257\n",
       "4247  пиздец   -6.269382\n",
       "444    блядь   -6.277723\n",
       "920      всё   -6.301655"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_3 = pd.DataFrame({\n",
    "    'feature': vectorizer.get_feature_names_out(), \n",
    "    'importance': model_3.feature_log_prob_[1]    \n",
    "})\n",
    "importance_3.sort_values('importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       951\n",
      "         1.0       0.74      0.83      0.78       491\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.82      0.84      0.83      1442\n",
      "weighted avg       0.85      0.84      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = RandFor(n_estimators=120, criterion='entropy')\n",
    "model_4.fit(x_train, y_train)\n",
    "preds_4 = model_1.predict(x_test)\n",
    "print(classification_report(y_test, preds_4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>0.007980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>0.007889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>0.005899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>0.005414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>0.004817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>блядь</td>\n",
       "      <td>0.004607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>сука</td>\n",
       "      <td>0.004502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>например</td>\n",
       "      <td>0.004494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>знаю</td>\n",
       "      <td>0.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>блять</td>\n",
       "      <td>0.004239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "7180     хохлы    0.007980\n",
       "7178    хохлов    0.007889\n",
       "3332     нахуй    0.005899\n",
       "8          ...    0.005414\n",
       "4247    пиздец    0.004817\n",
       "444      блядь    0.004607\n",
       "6468      сука    0.004502\n",
       "3274  например    0.004494\n",
       "2006      знаю    0.004363\n",
       "445      блять    0.004239"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_4 = pd.DataFrame({\n",
    "    'feature': vectorizer.get_feature_names_out(), \n",
    "    'importance': model_4.feature_importances_    \n",
    "})\n",
    "importance_4.sort_values('importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывожу по 10 самых токсичных, чтобы оценить, что там дальше, чем 5 (и не подкручиваю стоп-слова далее). Спорным может показаться токен \"...\", но, как кажется, он как раз вполне может говорить о токсичности. Нецензурные и оскорбительные слова происходят из исходных данных комментариев, сожалею"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
