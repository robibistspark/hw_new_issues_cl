{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг \\<start>  \n",
    "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
    "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter as C\n",
    "from scipy.sparse import lil_matrix, csc_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lenta.txt\", encoding='utf8') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                       in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in \\\n",
    "                       normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 32250/32250 [00:04<00:00, 6735.67it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_sent = []\n",
    "for sent in tqdm(sent_tokenize(corpus[:5000000])):\n",
    "    corpus_sent.append(['<start>'] * 2 + normalize(sent) + ['<end>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> <start> бои у сопоцкина и друскеник закончились отступлением германцев <end>\n"
     ]
    }
   ],
   "source": [
    "print(*corpus_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(corpus_sent, test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к генерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrammer(tokens, n=3):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(\" \".join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32230/32230 [00:01<00:00, 27849.71it/s]\n"
     ]
    }
   ],
   "source": [
    "unigrams = C()\n",
    "bigrams = C()\n",
    "trigrams = C()\n",
    "\n",
    "for sent in tqdm(train):\n",
    "    unigrams.update(sent)\n",
    "    bigrams.update(ngrammer(sent, n=2))\n",
    "    trigrams.update(ngrammer(sent, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 551592/551592 [00:02<00:00, 248689.00it/s]\n"
     ]
    }
   ],
   "source": [
    "matrix_bi_uni = lil_matrix(\n",
    "    (len(bigrams), len(unigrams))\n",
    ")\n",
    "\n",
    "id2word = list(unigrams)\n",
    "word2id_ = {word:i for i, word in enumerate(id2word)}\n",
    "\n",
    "id2bigram_ = list(bigrams)\n",
    "bigram2id = {bigram:i for i, bigram in enumerate(id2bigram_)}\n",
    "\n",
    "for trigram in tqdm(trigrams):\n",
    "    bigram, word = trigram.rsplit(\" \", 1)\n",
    "    matrix_bi_uni[bigram2id[bigram], word2id_[word]] = \\\n",
    "        (trigrams[trigram] / bigrams[bigram])\n",
    "\n",
    "matrix_bi_uni = csc_matrix(matrix_bi_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<380157x71955 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 551592 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bi_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, bigram2id, n=200):\n",
    "    text = ['<start>', '<start>']\n",
    "    current_idx = bigram2id['<start> <start>']\n",
    "    for i in range(n):\n",
    "        # choose random idx to continue, append the word to text\n",
    "        chosen_idx = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        chosen = id2word[chosen_idx]\n",
    "        text.append(chosen)\n",
    "        if chosen != '<end>':\n",
    "            current_idx = bigram2id[text[-2] + ' ' + text[-1]]\n",
    "        else:\n",
    "            current_idx = bigram2id['<start> <start>']\n",
    "            text.extend(['<start>', '<start>'])\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробная генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " еще две упаковки со взрывчаткой прорваться из горных районов чечни для встречи нового года когда он в интервью риа новости сообщили в центре таллина трое преступников в масках ворвались в салон ранили водителя забрали у пассажиров 60 тысяч рублей и в великую отечественную войну \n",
      "  с точки зрения эмоциональной привлекательности продуктов и те же годы реставрационные работы в наиболее тяжелом состоянии с нейсправиться сказал министр для беженцевв ингушетию будут доставлены в пригород бишкека \n",
      "  что касается представителей организаций борющихся за права больных спидом \n",
      "  как заявили интерфаксу в российском информационном пресс-центре объявил начальник центра общественных связей фсб россии по ростовской области добавляет рбк полностью отрицают версию о том что были предотвращены взрывы на железнодорожных станциях гудермес терек наурская червленая \n",
      "  однако примет ли милошевич это приглашение \n",
      "  я думаю что мы делаем абсолютно соответствует нормам законаи конституции подчеркнул он \n",
      "  такое заявление сделал сам примаков сообщил что все внимание сейчас приковано к ним привлечены армия флот добровольцы \n",
      "  однако нарушитель был задержан 29 октября ограничения на европейские музыкальные записи через сеть собственных магазинов и жилых домов отцов больших семей почтенных граждан \n",
      "  это должно выражаться в повышении прежде всего icann и европейских cctld при минимуме участия государства 3 мы надеемся\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_bi_uni, id2word, bigram2id).replace('<end>', '\\n').replace('<start> <start>', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное наблюдение -- это то, что после конца предложения, согласно нашей процедуре, могут получаться предложения, которые вообще не связаны с предыдущим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к оценке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba_markov(tokenized_text, word_counts, bigram_counts, trigram_counts):\n",
    "    prob = 0\n",
    "    for trigram in ngrammer(['<start>'] * 2 + tokenized_text + ['<end>'], n=3):\n",
    "        word1, word2, word3 = trigram.split()\n",
    "        bigram = word1 + ' ' + word2\n",
    "        if bigram in bigram_counts and trigram in trigram_counts:\n",
    "            prob += np.log(trigram_counts[trigram] / bigram_counts[bigram])\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    return prob, len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> <start> это дебют мендеса в кино <end>\n"
     ]
    }
   ],
   "source": [
    "print(*test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86654.40493966118"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_joint_proba_markov(test[0], unigrams, bigrams, trigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка средней перплексии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 740.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0, perplexity 86654.405\n",
      "\n",
      "<start> <start> это дебют мендеса в кино <end>\n",
      "\n",
      "\n",
      "Test 1, perplexity 18201.565\n",
      "\n",
      "<start> <start> таким образом поскольку праздничный день 7 ноября объявленный президентом рф днем согласия и примирения совпадает с выходным понедельник 8 ноября становится нерабочим днем 5 ноября вступил в силу приговор головинского межмуниципального суда москвы в отношении музыканта ильи гофмана сообщает риа новости <end>\n",
      "\n",
      "\n",
      "Test 2, perplexity 480.124\n",
      "\n",
      "<start> <start> как сообщает риа новости приговор был вынесен с учетом личности подсудимого состояния его здоровья и того обстоятельства что гофман раскаялся первый заместитель начальника генштаба вооруженных сил рф генерал-полковник валерий манилов назвал в пятницу на брифинге в росинформцентре цифры потерь федеральных войск на северном кавказе с начала боевых действий в дагестане до настоящего времени <end>\n",
      "\n",
      "\n",
      "Test 3, perplexity 27241.344\n",
      "\n",
      "<start> <start> по данным гершвина больше остальных стран от проблемы-2000 могут пострадать россия украина индонезия и китай <end>\n",
      "\n",
      "\n",
      "Test 4, perplexity 34850.551\n",
      "\n",
      "<start> <start> по мнению ющенко предъявляемые сейчас к украине требования об оплате российских энергоносителей вполне закономерны <end>\n",
      "\n",
      "\n",
      "Test 5, perplexity 22918.842\n",
      "\n",
      "<start> <start> бхутто нарушившая законы объявлена в розыск по нескольким судебным делам и сейчас находится за пределами страны <end>\n",
      "\n",
      "\n",
      "Test 6, perplexity 52025.567\n",
      "\n",
      "<start> <start> конечно таких людей нужно искать отметил он <end>\n",
      "\n",
      "\n",
      "Test 7, perplexity 43183.214\n",
      "\n",
      "<start> <start> врачи по его словам меры сверхосторожности но характер президента такой президент не любит болеть <end>\n",
      "\n",
      "\n",
      "Test 8, perplexity 20287.81\n",
      "\n",
      "<start> <start> это было свободное обсуждение наболевших тем подчеркнул он по окончании встречи консультации по формированию руководства госдумы третьего созыва завершатся 21 или 22 декабря <end>\n",
      "\n",
      "\n",
      "Test 9, perplexity 2051.321\n",
      "\n",
      "<start> <start> напомним что ранее о своих планах по покупке мира говорил бизнесмен уолт андерсон представляющий таинственную компанию даже название которой разные сми произносят по-разному то ли golden apple то ли gold appel то ли golden apple <end>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_perpl = 0\n",
    "for i in tqdm(range(len(test))):\n",
    "    perpl = perplexity(*compute_joint_proba_markov(test[i], unigrams, bigrams, trigrams))\n",
    "    mean_perpl += perpl\n",
    "    if i < 10:\n",
    "        print(f'Test {i}, perplexity {round(perpl, 3)}')\n",
    "        print()\n",
    "        print(*test[i])\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22320.925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_perpl / len(test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Могло бы быть и лучше, но неплохо. Есть доля случайности в выборке (при делении на \"обучающую\" и тестовую)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова. \n",
    "Сравните получаемый результат с первым заданием. \n",
    "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
